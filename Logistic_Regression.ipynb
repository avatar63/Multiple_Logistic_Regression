{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import Necessary aaaaand Not so Necessary Libraries\n"
      ],
      "metadata": {
        "id": "nyZWo8qXcXOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CrnY1fTvjEc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, log_loss, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing Stage\n"
      ],
      "metadata": {
        "id": "W_J03xfXz15v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic EDA to understand:\n",
        "\n",
        "\n",
        "*   Missing Data\n",
        "*   Types of Data\n",
        "*   Required Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "R6JWDs2NckEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"weatherAUS.csv\")\n",
        "data.info()"
      ],
      "metadata": {
        "id": "jP3QsA_uzLEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2f1bbf-cc09-4385-f404-d8608359ed5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Date           145460 non-null  object \n",
            " 1   Location       145460 non-null  object \n",
            " 2   MinTemp        143975 non-null  float64\n",
            " 3   MaxTemp        144199 non-null  float64\n",
            " 4   Rainfall       142199 non-null  float64\n",
            " 5   Evaporation    82670 non-null   float64\n",
            " 6   Sunshine       75625 non-null   float64\n",
            " 7   WindGustDir    135134 non-null  object \n",
            " 8   WindGustSpeed  135197 non-null  float64\n",
            " 9   WindDir9am     134894 non-null  object \n",
            " 10  WindDir3pm     141232 non-null  object \n",
            " 11  WindSpeed9am   143693 non-null  float64\n",
            " 12  WindSpeed3pm   142398 non-null  float64\n",
            " 13  Humidity9am    142806 non-null  float64\n",
            " 14  Humidity3pm    140953 non-null  float64\n",
            " 15  Pressure9am    130395 non-null  float64\n",
            " 16  Pressure3pm    130432 non-null  float64\n",
            " 17  Cloud9am       89572 non-null   float64\n",
            " 18  Cloud3pm       86102 non-null   float64\n",
            " 19  Temp9am        143693 non-null  float64\n",
            " 20  Temp3pm        141851 non-null  float64\n",
            " 21  RainToday      142199 non-null  object \n",
            " 22  RainTomorrow   142193 non-null  object \n",
            "dtypes: float64(16), object(7)\n",
            "memory usage: 25.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we can tell that the dataset consists of several incomplete values that would require imputation.\n",
        "\n",
        "Further, there are 16 float64 datatypes and 7 objects. So we make our imputing and encoding decisions based on that."
      ],
      "metadata": {
        "id": "MLBqkpEndPUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoding Categorical Data\n",
        "Making use of OneHotEncoding for different values for all categorical columns. The Dummy Variable count is taken care of by the model itself.\n"
      ],
      "metadata": {
        "id": "bMK7cRLrc3mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_data=[\"Location\",\"WindGustDir\",\"WindDir9am\",\"WindDir3pm\",\"RainToday\"]\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "for col in cat_data:\n",
        "  # Transform the categorical data\n",
        "  transformed_data = encoder.fit_transform(data[[col]])\n",
        "\n",
        "  # Convert the sparse matrix to a dense array\n",
        "  transformed_data = transformed_data.toarray()\n",
        "\n",
        "  # Create a DataFrame from the transformed data\n",
        "  df_transformed = pd.DataFrame(transformed_data, columns=encoder.get_feature_names_out([col]))\n",
        "  data.drop(col,axis=1)\n",
        "  # Concatenate the transformed data with the original DataFrame\n",
        "  data = pd.concat([data, df_transformed], axis=1)\n",
        "\n",
        "  # Remove the original categorical column\n",
        "  data = data.drop(col, axis=1)"
      ],
      "metadata": {
        "id": "JDlNKSLW5_9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our initial look at the dataset we can tell that in several but not too many rows the dependent variable itself is absent. We can delete the rows that have the missing dependent variable for simpler computation."
      ],
      "metadata": {
        "id": "ZJKvkVJVdJaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['RainTomorrow'], inplace=True)\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85PT0_IN0LRQ",
        "outputId": "25eaa03f-c299-442c-cfc5-a05a1b1a9735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 142193 entries, 0 to 145458\n",
            "Columns: 121 entries, Date to RainToday_nan\n",
            "dtypes: float64(119), object(2)\n",
            "memory usage: 132.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imputing values for Numerical Data\n",
        "\n",
        "We use the mean for each column to enter our missing values."
      ],
      "metadata": {
        "id": "ufK-z5ZseP3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_imputer = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
        "\n",
        "num_data=['MinTemp','MaxTemp','Rainfall','Evaporation','Sunshine','WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Cloud9am','Cloud3pm','Temp9am','Temp3pm']\n",
        "for column in num_data:\n",
        "  data[column]=float_imputer.fit_transform(data[[column]])\n"
      ],
      "metadata": {
        "id": "plJLYGnT2pbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing Data\n",
        "\n",
        "Since our data is now processed and complete, we can categorise them into dependent and independent variables (X and y)"
      ],
      "metadata": {
        "id": "iuEqWgtY6ANP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = data.iloc[:,:-1]\n",
        "X=X.drop([\"Date\",\"RainTomorrow\"],axis=1)\n",
        "print(X)\n",
        "y = data.iloc[:,-1]\n",
        "y=y.values"
      ],
      "metadata": {
        "id": "ZgOvmpsW4khK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc6dad4-975c-4084-9715-6f90e4ed4b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
            "0          13.4     22.9       0.6     5.469824  7.624853           44.0   \n",
            "1           7.4     25.1       0.0     5.469824  7.624853           44.0   \n",
            "2          12.9     25.7       0.0     5.469824  7.624853           46.0   \n",
            "3           9.2     28.0       0.0     5.469824  7.624853           24.0   \n",
            "4          17.5     32.3       1.0     5.469824  7.624853           41.0   \n",
            "...         ...      ...       ...          ...       ...            ...   \n",
            "145454      3.5     21.8       0.0     5.469824  7.624853           31.0   \n",
            "145455      2.8     23.4       0.0     5.469824  7.624853           31.0   \n",
            "145456      3.6     25.3       0.0     5.469824  7.624853           22.0   \n",
            "145457      5.4     26.9       0.0     5.469824  7.624853           37.0   \n",
            "145458      7.8     27.0       0.0     5.469824  7.624853           28.0   \n",
            "\n",
            "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
            "0               20.0          24.0         71.0         22.0  ...   \n",
            "1                4.0          22.0         44.0         25.0  ...   \n",
            "2               19.0          26.0         38.0         30.0  ...   \n",
            "3               11.0           9.0         45.0         16.0  ...   \n",
            "4                7.0          20.0         82.0         33.0  ...   \n",
            "...              ...           ...          ...          ...  ...   \n",
            "145454          15.0          13.0         59.0         27.0  ...   \n",
            "145455          13.0          11.0         51.0         24.0  ...   \n",
            "145456          13.0           9.0         56.0         21.0  ...   \n",
            "145457           9.0           9.0         53.0         24.0  ...   \n",
            "145458          13.0           7.0         51.0         24.0  ...   \n",
            "\n",
            "        WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  WindDir3pm_SW  \\\n",
            "0                 0.0             0.0             0.0            0.0   \n",
            "1                 0.0             0.0             0.0            0.0   \n",
            "2                 0.0             0.0             0.0            0.0   \n",
            "3                 0.0             0.0             0.0            0.0   \n",
            "4                 0.0             0.0             0.0            0.0   \n",
            "...               ...             ...             ...            ...   \n",
            "145454            0.0             0.0             0.0            0.0   \n",
            "145455            0.0             0.0             0.0            0.0   \n",
            "145456            0.0             0.0             0.0            0.0   \n",
            "145457            0.0             0.0             0.0            0.0   \n",
            "145458            0.0             0.0             0.0            0.0   \n",
            "\n",
            "        WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  WindDir3pm_nan  \\\n",
            "0                0.0             1.0             0.0             0.0   \n",
            "1                0.0             0.0             1.0             0.0   \n",
            "2                0.0             0.0             1.0             0.0   \n",
            "3                0.0             0.0             0.0             0.0   \n",
            "4                0.0             0.0             0.0             0.0   \n",
            "...              ...             ...             ...             ...   \n",
            "145454           0.0             0.0             0.0             0.0   \n",
            "145455           0.0             0.0             0.0             0.0   \n",
            "145456           0.0             0.0             0.0             0.0   \n",
            "145457           0.0             1.0             0.0             0.0   \n",
            "145458           0.0             0.0             0.0             0.0   \n",
            "\n",
            "        RainToday_No  RainToday_Yes  \n",
            "0                1.0            0.0  \n",
            "1                1.0            0.0  \n",
            "2                1.0            0.0  \n",
            "3                1.0            0.0  \n",
            "4                1.0            0.0  \n",
            "...              ...            ...  \n",
            "145454           1.0            0.0  \n",
            "145455           1.0            0.0  \n",
            "145456           1.0            0.0  \n",
            "145457           1.0            0.0  \n",
            "145458           1.0            0.0  \n",
            "\n",
            "[142193 rows x 118 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoding the y variable"
      ],
      "metadata": {
        "id": "YHVi809LI0_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder=LabelEncoder()\n",
        "y=label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Z4uyKuCVI0sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split The Dataset Into Training And Testing Data"
      ],
      "metadata": {
        "id": "eJAfYGkcfCWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
      ],
      "metadata": {
        "id": "6I2rgFOY5A8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load and fit the model to our training data"
      ],
      "metadata": {
        "id": "EbdGRpp0fN2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "cmbNg8fb5Mon",
        "outputId": "08514f69-c1cc-48c4-9b49-829f8fe2598f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation and Testing\n",
        "\n",
        "Using several methods/metrics that come with scikit-learn we may now evaluate our model"
      ],
      "metadata": {
        "id": "p3dhwBT-fUui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "--- Basic Evaluation using test set\n",
        "\n"
      ],
      "metadata": {
        "id": "U2txlR8bfgGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "type(y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "SYLf2-Gv5eTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff3a88d-19b0-4879-8e40-ddb1f26561b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9896972467386336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mu_VWz1XRf7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}